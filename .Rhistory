#mardia
mvn(iris, mvnTest = "mardia")
#perspective andn contour plot
mvn(iris[,2:3], mvnTest = "hz", multivariatePlot = "persp")
##4.24
hematol = read.table("T4_3_HEMATOL.DAT")
###rename the data as you wish, in here we rename to "hematol"
View(hematol)
View(probe)
## 4.21
probe = read.table("T3_6_PROBE.DAT")
probe = probe[,-1]
qqnorm(probe$V2)
qqnorm(probe$V2)
qqnorm(probe$V3)
qqnorm(probe$V4)
qqnorm(probe$V5)
qqnorm(probe$V6)
library(moments)
# skewness and kurtosis
skewness(probe)
kurtosis(probe)
#kurtosis<3 means the distribution is flatter than the normal distribution while kurtosis>3 will have
#higher peak than normal distribution
###Skewness and Kurtosis Representation###
set.seed(5)
# normal
x = rnorm(1000, 0,1)
hist(x, main="Normal: Symmetrical", freq=FALSE)
lines(density(x), col='red', lwd=3)
abline(v = c(mean(x),median(x)),  col=c("green", "blue"), lty=c(2,2), lwd=c(3, 3))
# exponential (positive skewness)
x = rexp(1000,1)
hist(x, main="Exponential: Positive Skew", freq=FALSE)
lines(density(x), col='red', lwd=3)
abline(v = c(mean(x),median(x)),  col=c("green", "blue"), lty=c(2,2), lwd=c(3, 3))
# beta (negative skewness)
x= rbeta(10000,5,2)
hist(x, main="Beta: Negative Skew", freq=FALSE)
lines(density(x), col='red', lwd=3)
abline(v = c(mean(x),median(x)),  col=c("green", "blue"), lty=c(2,2), lwd=c(3, 3))
agostino.test(probe)
agostino.test(probe$V2)
#d'agostino test
agostino.test
#d'agostino test
agostino.test(probe$V2)
agostino.test(probe$V3)
agostino.test(probe$V4)
agostino.test(probe$V5)
agostino.test(probe$V6)
#lin-mudholkar test
lin.mudholkar.normality.test.simple = function(sample.r
,sample.size
,method = c("lin-mudholkar-1980")
,alternative = c("two.sided","less","greater")
,conf.level = 0.95
) {
validate.htest.alternative(alternative = alternative)
n = sample.size
r = sample.r
Y = -11.7/n + 55.06/n^2
S = sqrt(3/n - 7.324/n^2 + 53.005/n^3)
a = 24/Y - 3
c = .5 * log((1+r)/(1-r))
b = (-24 * c) / (S*Y)
if (n < 4) {
roots = rep(NA,3)
} else {
roots = polyroot(c(b,a,0,1))
}
roots[which(Im(roots) == 0)]
roots = Re(roots)
roots = roots[order(abs(roots))]
z = roots[1]
p.value = if (alternative[1] == "two.sided") {
tmp = pnorm(z)
min(tmp,1-tmp)*2
} else if (alternative[1] == "greater") {
pnorm(z,lower.tail = FALSE)
} else if (alternative[1] == "less") {
pnorm(z,lower.tail = TRUE)
} else {
NA
}
retval = list(data.name   = "input data",
statistic   = z,
estimate    = c(sample.size = n,
r = r, b = b, a = a, S = S, Y = Y, root.1 = roots[1],
root.2 = roots[2],root.3 = roots[3]),
parameter   = 0,
p.value     = p.value,
null.value  = 0,
alternative = alternative[1],
method      = "Lin-Mudholkar Normality Test"
)
names(retval$statistic) = "z statistic"
names(retval$null.value) = "z"
names(retval$parameter) = "null hypothesis z"
class(retval) = "htest"
retval
}
lin.mudholkar.normality.test.simple(probe$V2, 10)
install.packages("BurStMisc")
#lin-mudholkar test
validate.htest.alternative <- function(alternative, allowed = c("two.sided", "less", "greater")) {
if (length(alternative) < 1) {
stop("Empty alternative parameter")
}
if (length(alternative) > 1) {
alternative <- alternative[1]
}
if (is.na(alternative)) {
stop("alternative parameter is NA")
}
if (!is.character(alternative)) {
stop("alternative parameter is not a character string")
}
if (!(alternative %in% allowed)) {
stop(paste("alternative parameter is invalid. Use", paste(shQuote(allowed, type="cmd"), collapse = ", ") ))
}
}
lin.mudholkar.normality.test.simple = function(sample.r
,sample.size
,method = c("lin-mudholkar-1980")
,alternative = c("two.sided","less","greater")
,conf.level = 0.95)
{
validate.htest.alternative(alternative = alternative)
n = sample.size
r = sample.r
Y = -11.7/n + 55.06/n^2
S = sqrt(3/n - 7.324/n^2 + 53.005/n^3)
a = 24/Y - 3
c = .5 * log((1+r)/(1-r))
b = (-24 * c) / (S*Y)
if (n < 4) {
roots = rep(NA,3)
} else {
roots = polyroot(c(b,a,0,1))
}
roots[which(Im(roots) == 0)]
roots = Re(roots)
roots = roots[order(abs(roots))]
z = roots[1]
p.value = if (alternative[1] == "two.sided") {
tmp = pnorm(z)
min(tmp,1-tmp)*2
} else if (alternative[1] == "greater") {
pnorm(z,lower.tail = FALSE)
} else if (alternative[1] == "less") {
pnorm(z,lower.tail = TRUE)
} else {
NA
}
retval = list(data.name   = "input data",
statistic   = z,
estimate    = c(sample.size = n,
r = r, b = b, a = a, S = S, Y = Y, root.1 = roots[1],
root.2 = roots[2],root.3 = roots[3]),
parameter   = 0,
p.value     = p.value,
null.value  = 0,
alternative = alternative[1],
method      = "Lin-Mudholkar Normality Test"
)
names(retval$statistic) = "z statistic"
names(retval$null.value) = "z"
names(retval$parameter) = "null hypothesis z"
class(retval) = "htest"
retval
}
lin.mudholkar.normality.test.simple(probe$V2, 10)
lin.mudholkar.normality.test.simple(probe$V2)
lin.mudholkar.normality.test.simple(probe$V2, 1000)
lin.mudholkar.normality.test.simple(probe$V2, 11)
lin.mudholkar.normality.test.simple(probe$V2, 1)
lin.mudholkar.normality.test.simple(probe$V2, 2)
lin.mudholkar.normality.test.simple(probe$V2, 3)
lin.mudholkar.normality.test.simple(probe$V3, 3)
lin.mudholkar.normality.test.simple(probe$V4, 3)
lin.mudholkar.normality.test.simple(probe$V4, 4)
lin.mudholkar.normality.test.simple(probe$V4, 2)
lin.mudholkar.normality.test.simple(probe$V5, 2)
lin.mudholkar.normality.test.simple(probe$V6, 2)
lin.mudholkar.normality.test.simple(probe$V6, 1)
lin.mudholkar.normality.test.simple <- function(sample.r
,sample.size
,method = c("lin-mudholkar-1980")
,alternative = c("two.sided","less","greater")
,conf.level = 0.95
) {
validate.htest.alternative(alternative = alternative)
n <- sample.size
r <- sample.r
Y <- -11.7/n + 55.06/n^2
S <- sqrt(3/n - 7.324/n^2 + 53.005/n^3)
a <- 24/Y - 3
c <- .5 * log((1+r)/(1-r))
b <- (-24 * c) / (S*Y)
if (n < 4) {
roots <-rep(NA,3)
} else {
roots <- polyroot(c(b,a,0,1))
}
roots[which(Im(roots) == 0)]
roots <- Re(roots)
roots <- roots[order(abs(roots))]
z <- roots[1]
p.value <- if (alternative[1] == "two.sided") {
tmp<-pnorm(z)
min(tmp,1-tmp)*2
} else if (alternative[1] == "greater") {
pnorm(z,lower.tail = FALSE)
} else if (alternative[1] == "less") {
pnorm(z,lower.tail = TRUE)
} else {
NA
}
retval<-list(data.name   = "input data",
statistic   = z,
estimate    = c(sample.size = n
,r = r
,b = b
,a = a
,S = S
,Y = Y
,root.1 = roots[1]
,root.2 = roots[2]
,root.3 = roots[3]
),
parameter   = 0,
p.value     = p.value,
null.value  = 0,
alternative = alternative[1],
method      = "Lin-Mudholkar Normality Test"
)
names(retval$statistic) <- "z statistic"
names(retval$null.value) <- "z"
names(retval$parameter) <- "null hypothesis z"
class(retval)<-"htest"
retval
}
lin.mudholkar.normality.test.simple(probe$V6, 1)
lin.mudholkar.normality.test.simple(probe$V6, 0)
lin.mudholkar.normality.test.simple(probe$V6, 0)
lin.mudholkar.normality.test.simple(probe$V6, 4)
lin.mudholkar.normality.test.simple(probe$V6, 5)
lin.mudholkar.normality.test.simple(probe$V6, 6)
lin.mudholkar.normality.test.simple(probe$V6, 3)
lin.mudholkar.normality.test.simple(probe$V6, 2)
View(calcium)
##Testing when the covariance matrix is known
#similar to univariate case, lets start with testing means when the covariance is known.
read.table("T3_4_CALCIUM.DAT", calcium)
T3_4_CALCIUM <- read.table("G:/My Drive/Github/Multivariate-Statistics-R/T3_4_CALCIUM.DAT", quote="\"", comment.char="")
View(T3_4_CALCIUM)
calcium <- read.table("G:/My Drive/Github/Multivariate-Statistics-R/T3_4_CALCIUM.DAT", quote="\"", comment.char="")
View(calcium)
##Testing when the covariance matrix is known
#similar to univariate case, lets start with testing means when the covariance is known.
read.table("T3_4_CALCIUM.DAT", calcium)
##Testing when the covariance matrix is known
#similar to univariate case, lets start with testing means when the covariance is known.
calcium = read.table("T3_4_CALCIUM.DAT")
###Multivariate Test on Two Mean Vectors###
#Source : https://rpubs.com/SaraGarcesCespedes/587169 #
#Materials : Methods_of_Multivariate_Analysis-_3rd_Edition Rencher & Christensen #
update(R)
###Multivariate Test on Two Mean Vectors###
#Source : https://rpubs.com/SaraGarcesCespedes/587169 #
#Materials : Methods_of_Multivariate_Analysis-_3rd_Edition Rencher & Christensen #
updateR()
version
calcium = read.table("T3_4_CALCIUM.DAT")[,-1]
View(calcium)
##Testing when the covariance matrix is known
#similar to univariate case, lets start with testing means when the covariance is known.
#simulate the samples
meanvect = c(13,5,65,1250)
##Testing when the covariance matrix is known
#similar to univariate case, lets start with testing means when the covariance is known.
#simulate the samples
meanvect = c(13,5,1250)
cov_m = matrix(c(24,123,456,123,53,632,456,632,3257), ncol = 3)
cov_m
eigen(cov_m)
cov_m = matrix(c(24,123,4,123,53,632,4,632,3257), ncol = 3)
eigen(cov_m)
cov_m = matrix(c(24,123,4,123,53,62,4,62,3257), ncol = 3)
eigen(cov_m)
cov_m = matrix(c(24,123,47,123,53,62,47,62,3257), ncol = 3)
eigen(cov_m)
cov_m = matrix(c(24,123,47,123,53,162,47,162,3257), ncol = 3)
eigen(cov_m)
cov_m = matrix(c(124,123,47,
123,53,162,
47,162,3257), ncol = 3)
eigen(cov_m)
cov_m = matrix(c(124,123,47,
123,203,162,
47,162,3257), ncol = 3)
eigen(cov_m)
gen.data = function(mu, sigma, n) {
dt1 = MASS::mvrnorm(n1, mu=mu1, Sigma=sigma1) # Population 1
return(dt1)
}
gen.data(meanvect, cov_m, 300)
#define a function to sample from a MN dist
gen.data = function(mu, sigma, n) {
dt1 = MASS::mvrnorm(n, mu=mu, Sigma=sigma) # Population 1
return(dt1)
}
gen.data(meanvect, cov_m, 300)
library(rgl)
#define a function to sample from a MN dist
set.seed(123)
gen.samples = gen.data(meanvect, cov_m, 300)
plot3d(gen.samples)
plot3d(gen.samples, xlab = v1, ylab = v2, zlab = v3)
plot3d(gen.samples, xlab = v1, ylab = v2, zlab = v3)
plot3d(gen.samples)
colenames(gen.samples) = c("v1", "v2", "v3")
colnames(gen.samples) = c("v1", "v2", "v3")
plot3d(gen.samples)
library(car)
library(RColorBrewer)
library(stats)
library(gridExtra)
library(tidyverse)
gen.data = function(mu, sigma, n) {
require(MASS)
dt1 = mvrnorm(n, mu=mu, Sigma=sigma) # Population 1
return(dt1)
}
###Exercise from Methods_of_Multivariate_Analysis-_3rd_Edition Rencher & Christensen###
library(fBasics)
## 3.11
cov(calcium)#covariance matrix
det(cov(calcium))#generalized sample variance
tr(cov(calcium))#total sample variance
z
apply(z, 2,mean)
cov(z)
#using equation 3.62 and 3.64
mean.calc = matrix(apply(calcium, 2, mean), ncol = 1)
sd.calc = matrix(cov(calcium), ncol = 3)
#correlation matrix
solve(matrix(sqrt(diag(diag(cov(z)))), ncol = 3))%*%cov(z)%*%solve(matrix(sqrt(diag(diag(cov(z)))), ncol = 3))
cor(z)
mult320%*%mean.bone
covz.bone = mult320%*%sd.bone%*%t(mult320)
solve(matrix(sqrt(diag(diag(covz.bone))), ncol = 3))%*%covz.bone%*%solve(matrix(sqrt(diag(diag(covz.bone))), ncol = 3))
cor(bone%*%t(mult320))
str(sim.mn.data)
##visualizing the multivariate normal data
#after generating MN data, we can visualize the data
#since we are limited in 3dimensional representation, we are limited to only use until first 3 variables
#of the simulated data from before.
#it is guaranteed that marginal distributions from MN is always normal(see Methods_of_Multivariate_Analysis-_3rd_Edition Rencher & Christensen )
#2d contour
sim.mn.kernel = kde2d(sim.mn.data[,1], sim.mn.data[,3], n = 150) #calculate kernel density estimate
###multivariate normal distribution###
library(mvtnorm)
library(MVN)
library(JWileymisc)
library(MASS)
library(dplyr)
library(ellipse)
library(rgl)
##visualizing the multivariate normal data
#after generating MN data, we can visualize the data
#since we are limited in 3dimensional representation, we are limited to only use until first 3 variables
#of the simulated data from before.
#it is guaranteed that marginal distributions from MN is always normal(see Methods_of_Multivariate_Analysis-_3rd_Edition Rencher & Christensen )
#2d contour
sim.mn.kernel = kde2d(sim.mn.data[,1], sim.mn.data[,3], n = 150) #calculate kernel density estimate
image(sim.mn.kernel) #heatmap based on the kernel estimate
contour(sim.mn.kernel, add = T) #contour plot added above the heatmap
#next is the "clean" version of bivariate normal distribution which using ellipse function
#in addition, confidence intervals is also added
rho = cor(sim.mn.data[,1:2])
y_on_x = lm(high ~ low, sim.mn.data)    # Regression Y ~ X
x_on_y = lm(low ~ high, sim.mn.data)    # Regression X ~ Y
plot_legend = c("99% CI green", "95% CI red","90% CI blue",
"Y on X black", "X on Y brown")
plot(sim.mn.data[,1:2], xlab = "low", ylab = "high",
col = "dark blue",
main = "Bivariate Normal with Confidence Intervals")
lines(ellipse(rho), col="red")       # ellipse() from ellipse package
lines(ellipse(rho, level = .99), col="green")
lines(ellipse(rho, level = .90), col="blue")
abline(y_on_x)
abline(x_on_y, col="brown")
legend(3,1,legend=plot_legend,cex = .5, bty = "n")
#3d representation
persp(sim.mn.kernel, phi = 45, theta = 30, shade = .1, border = NA) # from base graphics package
#using interactive plot from RGL library
color2 = heat.colors(length(sim.mn.kernel$z))[rank(sim.mn.kernel$z)]
persp3d(x=sim.mn.kernel, col = color2)
###MN distribution exercises from Methods_of_Multivariate_Analysis-_3rd_Edition Rencher & Christensen
library(car)
library(rgl)
library(mgcv)
library(mvtnorm)
library(Hmisc)
library(matlib)
library(MVN)
library(moments)
set.seed(100)
## 4.10
mu = c(3,1,4)
sigma = matrix(c(6,1,-2,1,13,4,-2,4,4), nrow = 3, ncol = 3, byrow = T)
## 4.11
#simulate vector y from the defined multivariate normal dist
y = rmvnorm(1,mu , sigma,method=c("eigen", "svd", "chol"), pre0.9_9994 = FALSE)
#compute cholesky decomposition
t = chol(sigma)
#compute the new vector
z1 = solve(t(t))%*%t(y-mu)
z1
## 4.24
hematol = read.table("T4_3_HEMATOL.DAT")
View(hematol)
colnames(hematol) = NULL
hematol = as.matrix(hematol)
#mean vector n cov matrix
mean_hematol = apply(hematol,2,mean)
cov_hematol = cov(hematol)
#compute d[i]
d = matrix(data = 1, nrow = dim(hematol)[1])
for(i in 1:dim(hematol)[1]){
d[i] = t(hematol[i,]-mean_hematol)%*%solve(cov_hematol)%*%(hematol[i,]-mean_hematol)
}
d
dn = max(d)
dn
#compute u[i]
u = (51/50^2)*d
u = sort(u)
#compute v[i]
alpha = (dim(hematol)[2]-2)/(2*dim(hematol)[2])
beta = (dim(hematol)[1]-dim(hematol)[2]-3)/(2*(dim(hematol)[1]-dim(hematol)[2]-1))
v = (c(1:51)-alpha)/(dim(hematol)[1]-alpha-beta+1)
v
#plot (u[i],v[i])
plot(u, v)
#compute g[i,j]
sigma_hem = (50/51)*cov_hematol
g = matrix(data = 1, nrow = dim(hematol)[1], ncol = dim(hematol)[1])
for(i in 1:dim(hematol)[1]){
for(j in 1:i){
g[i,j] = t(hematol[i,]-mean_hematol)%*%solve(sigma_hem)%*%(hematol[j,]-mean_hematol)
g[j,i] = t(hematol[j,]-mean_hematol)%*%solve(sigma_hem)%*%(hematol[i,]-mean_hematol)
}
}
#compute b1 and b2
b1 = (1/51^2)*sum(g^3)
b2 = (1/51)*sum(diag(g)^2)
#using z
z1 = b1*(dim(hematol)[2]+1)*(dim(hematol)[1]+1)*(dim(hematol)[1]+3)/(6*((dim(hematol)[1]+1)*(dim(hematol)[2]+1)-6))
#z1~chisq(p(p+1)(p+2)/6)
df1 = (dim(hematol)[2]+1)*(dim(hematol)[2]+2)
pvalue1 = dchisq(z1,df1)
pvalue1
#using MVN package
mvn(data= hematol,mvnTest="royston")
#using MVN package
mvn(data= hematol)
#using MVN package
mvn(hematol)
#using MVN package
hematol
## 4.24
hematol = read.table("T4_3_HEMATOL.DAT")
mvn(hematol)
hematol = as.matrix(hematol)
mvn(hematol)
##Multivariate normality test
#there are several methods in which each of them has unique characteristics and may be better off used
#on certain type of data.
#mardia
mvn(iris, mvnTest = "mardia")
#testing outlier
scatter3d(hematol[,1], hematol[,3], hematol[,6], surface = FALSE)
T3_8_SONS <- read.table("G:/My Drive/Github/Multivariate-Statistics-R/T3_8_SONS.DAT", quote="\"", comment.char="")
View(T3_8_SONS)
cov(T3_8_SONS)
det(cov(T3_8_SONS))
tr(cov(T3_8_SONS))
###Exercise from Methods_of_Multivariate_Analysis-_3rd_Edition Rencher & Christensen###
library(fBasics)
tr(cov(T3_8_SONS))
det(cov(T3_8_SONS[,-4]))
apply(T3_8_SONS, 2, mean)
#using MVN package
mvn(data= hematol,mvnTest="royston") ###check mvn package logs
###MN distribution exercises from Methods_of_Multivariate_Analysis-_3rd_Edition Rencher & Christensen
library(car)
library(rgl)
library(MVN)
#using MVN package
mvn(data= hematol,mvnTest="royston") ###check mvn package logs
son2 = rbind(T3_8_SONS[,1:2], T3_8_SONS[,3:4])
T3_8_SONS[,1:2]
c(T3_8_SONS[,1:2])
T3_8_SONS = as.matrix(T3_8_SONS)
son2 = rbind(T3_8_SONS[,1:2], T3_8_SONS[,3:4])
son2
cov(son2)
mvn(son2)
mvn(son2, mvnTest = "mardia")

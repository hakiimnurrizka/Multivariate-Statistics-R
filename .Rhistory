eigen(cov_m)
cov_m = matrix(c(24,123,47,123,53,162,47,162,3257), ncol = 3)
eigen(cov_m)
cov_m = matrix(c(124,123,47,
123,53,162,
47,162,3257), ncol = 3)
eigen(cov_m)
cov_m = matrix(c(124,123,47,
123,203,162,
47,162,3257), ncol = 3)
eigen(cov_m)
gen.data = function(mu, sigma, n) {
dt1 = MASS::mvrnorm(n1, mu=mu1, Sigma=sigma1) # Population 1
return(dt1)
}
gen.data(meanvect, cov_m, 300)
#define a function to sample from a MN dist
gen.data = function(mu, sigma, n) {
dt1 = MASS::mvrnorm(n, mu=mu, Sigma=sigma) # Population 1
return(dt1)
}
gen.data(meanvect, cov_m, 300)
library(rgl)
#define a function to sample from a MN dist
set.seed(123)
gen.samples = gen.data(meanvect, cov_m, 300)
plot3d(gen.samples)
plot3d(gen.samples, xlab = v1, ylab = v2, zlab = v3)
plot3d(gen.samples, xlab = v1, ylab = v2, zlab = v3)
plot3d(gen.samples)
colenames(gen.samples) = c("v1", "v2", "v3")
colnames(gen.samples) = c("v1", "v2", "v3")
plot3d(gen.samples)
library(car)
library(RColorBrewer)
library(stats)
library(gridExtra)
library(tidyverse)
gen.data = function(mu, sigma, n) {
require(MASS)
dt1 = mvrnorm(n, mu=mu, Sigma=sigma) # Population 1
return(dt1)
}
###Exercise from Methods_of_Multivariate_Analysis-_3rd_Edition Rencher & Christensen###
library(fBasics)
## 3.11
cov(calcium)#covariance matrix
det(cov(calcium))#generalized sample variance
tr(cov(calcium))#total sample variance
z
apply(z, 2,mean)
cov(z)
#using equation 3.62 and 3.64
mean.calc = matrix(apply(calcium, 2, mean), ncol = 1)
sd.calc = matrix(cov(calcium), ncol = 3)
#correlation matrix
solve(matrix(sqrt(diag(diag(cov(z)))), ncol = 3))%*%cov(z)%*%solve(matrix(sqrt(diag(diag(cov(z)))), ncol = 3))
cor(z)
mult320%*%mean.bone
covz.bone = mult320%*%sd.bone%*%t(mult320)
solve(matrix(sqrt(diag(diag(covz.bone))), ncol = 3))%*%covz.bone%*%solve(matrix(sqrt(diag(diag(covz.bone))), ncol = 3))
cor(bone%*%t(mult320))
str(sim.mn.data)
##visualizing the multivariate normal data
#after generating MN data, we can visualize the data
#since we are limited in 3dimensional representation, we are limited to only use until first 3 variables
#of the simulated data from before.
#it is guaranteed that marginal distributions from MN is always normal(see Methods_of_Multivariate_Analysis-_3rd_Edition Rencher & Christensen )
#2d contour
sim.mn.kernel = kde2d(sim.mn.data[,1], sim.mn.data[,3], n = 150) #calculate kernel density estimate
###multivariate normal distribution###
library(mvtnorm)
library(MVN)
library(JWileymisc)
library(MASS)
library(dplyr)
library(ellipse)
library(rgl)
##visualizing the multivariate normal data
#after generating MN data, we can visualize the data
#since we are limited in 3dimensional representation, we are limited to only use until first 3 variables
#of the simulated data from before.
#it is guaranteed that marginal distributions from MN is always normal(see Methods_of_Multivariate_Analysis-_3rd_Edition Rencher & Christensen )
#2d contour
sim.mn.kernel = kde2d(sim.mn.data[,1], sim.mn.data[,3], n = 150) #calculate kernel density estimate
image(sim.mn.kernel) #heatmap based on the kernel estimate
contour(sim.mn.kernel, add = T) #contour plot added above the heatmap
#next is the "clean" version of bivariate normal distribution which using ellipse function
#in addition, confidence intervals is also added
rho = cor(sim.mn.data[,1:2])
y_on_x = lm(high ~ low, sim.mn.data)    # Regression Y ~ X
x_on_y = lm(low ~ high, sim.mn.data)    # Regression X ~ Y
plot_legend = c("99% CI green", "95% CI red","90% CI blue",
"Y on X black", "X on Y brown")
plot(sim.mn.data[,1:2], xlab = "low", ylab = "high",
col = "dark blue",
main = "Bivariate Normal with Confidence Intervals")
lines(ellipse(rho), col="red")       # ellipse() from ellipse package
lines(ellipse(rho, level = .99), col="green")
lines(ellipse(rho, level = .90), col="blue")
abline(y_on_x)
abline(x_on_y, col="brown")
legend(3,1,legend=plot_legend,cex = .5, bty = "n")
#3d representation
persp(sim.mn.kernel, phi = 45, theta = 30, shade = .1, border = NA) # from base graphics package
#using interactive plot from RGL library
color2 = heat.colors(length(sim.mn.kernel$z))[rank(sim.mn.kernel$z)]
persp3d(x=sim.mn.kernel, col = color2)
###MN distribution exercises from Methods_of_Multivariate_Analysis-_3rd_Edition Rencher & Christensen
library(car)
library(rgl)
library(mgcv)
library(mvtnorm)
library(Hmisc)
library(matlib)
library(MVN)
library(moments)
set.seed(100)
## 4.10
mu = c(3,1,4)
sigma = matrix(c(6,1,-2,1,13,4,-2,4,4), nrow = 3, ncol = 3, byrow = T)
## 4.11
#simulate vector y from the defined multivariate normal dist
y = rmvnorm(1,mu , sigma,method=c("eigen", "svd", "chol"), pre0.9_9994 = FALSE)
#compute cholesky decomposition
t = chol(sigma)
#compute the new vector
z1 = solve(t(t))%*%t(y-mu)
z1
## 4.24
hematol = read.table("T4_3_HEMATOL.DAT")
View(hematol)
colnames(hematol) = NULL
hematol = as.matrix(hematol)
#mean vector n cov matrix
mean_hematol = apply(hematol,2,mean)
cov_hematol = cov(hematol)
#compute d[i]
d = matrix(data = 1, nrow = dim(hematol)[1])
for(i in 1:dim(hematol)[1]){
d[i] = t(hematol[i,]-mean_hematol)%*%solve(cov_hematol)%*%(hematol[i,]-mean_hematol)
}
d
dn = max(d)
dn
#compute u[i]
u = (51/50^2)*d
u = sort(u)
#compute v[i]
alpha = (dim(hematol)[2]-2)/(2*dim(hematol)[2])
beta = (dim(hematol)[1]-dim(hematol)[2]-3)/(2*(dim(hematol)[1]-dim(hematol)[2]-1))
v = (c(1:51)-alpha)/(dim(hematol)[1]-alpha-beta+1)
v
#plot (u[i],v[i])
plot(u, v)
#compute g[i,j]
sigma_hem = (50/51)*cov_hematol
g = matrix(data = 1, nrow = dim(hematol)[1], ncol = dim(hematol)[1])
for(i in 1:dim(hematol)[1]){
for(j in 1:i){
g[i,j] = t(hematol[i,]-mean_hematol)%*%solve(sigma_hem)%*%(hematol[j,]-mean_hematol)
g[j,i] = t(hematol[j,]-mean_hematol)%*%solve(sigma_hem)%*%(hematol[i,]-mean_hematol)
}
}
#compute b1 and b2
b1 = (1/51^2)*sum(g^3)
b2 = (1/51)*sum(diag(g)^2)
#using z
z1 = b1*(dim(hematol)[2]+1)*(dim(hematol)[1]+1)*(dim(hematol)[1]+3)/(6*((dim(hematol)[1]+1)*(dim(hematol)[2]+1)-6))
#z1~chisq(p(p+1)(p+2)/6)
df1 = (dim(hematol)[2]+1)*(dim(hematol)[2]+2)
pvalue1 = dchisq(z1,df1)
pvalue1
#using MVN package
mvn(data= hematol,mvnTest="royston")
#using MVN package
mvn(data= hematol)
#using MVN package
mvn(hematol)
#using MVN package
hematol
## 4.24
hematol = read.table("T4_3_HEMATOL.DAT")
mvn(hematol)
hematol = as.matrix(hematol)
mvn(hematol)
##Multivariate normality test
#there are several methods in which each of them has unique characteristics and may be better off used
#on certain type of data.
#mardia
mvn(iris, mvnTest = "mardia")
#testing outlier
scatter3d(hematol[,1], hematol[,3], hematol[,6], surface = FALSE)
T3_8_SONS <- read.table("G:/My Drive/Github/Multivariate-Statistics-R/T3_8_SONS.DAT", quote="\"", comment.char="")
View(T3_8_SONS)
cov(T3_8_SONS)
det(cov(T3_8_SONS))
tr(cov(T3_8_SONS))
###Exercise from Methods_of_Multivariate_Analysis-_3rd_Edition Rencher & Christensen###
library(fBasics)
tr(cov(T3_8_SONS))
det(cov(T3_8_SONS[,-4]))
apply(T3_8_SONS, 2, mean)
#using MVN package
mvn(data= hematol,mvnTest="royston") ###check mvn package logs
###MN distribution exercises from Methods_of_Multivariate_Analysis-_3rd_Edition Rencher & Christensen
library(car)
library(rgl)
library(MVN)
#using MVN package
mvn(data= hematol,mvnTest="royston") ###check mvn package logs
son2 = rbind(T3_8_SONS[,1:2], T3_8_SONS[,3:4])
T3_8_SONS[,1:2]
c(T3_8_SONS[,1:2])
T3_8_SONS = as.matrix(T3_8_SONS)
son2 = rbind(T3_8_SONS[,1:2], T3_8_SONS[,3:4])
son2
cov(son2)
mvn(son2)
mvn(son2, mvnTest = "mardia")
###MN distribution exercises from Methods_of_Multivariate_Analysis-_3rd_Edition Rencher & Christensen
library(car)
library(rgl)
library(mgcv)
library(mvtnorm)
library(Hmisc)
library(matlib)
library(MVN)
library(moments)
#using MVN package
mvn(data= hematol,mvnTest="royston") ###check mvn package logs
#testing outlier
scatter3d(hematol[,1], hematol[,3], hematol[,6], surface = FALSE)
p.z2
p.z2 = dchisq(z2, 3) #Z2 is distributed as chisq(p) if null is true
z2 = n*t(mu.sam-mu)%*%solve(cov_m)%*%(mu.sam-mu)
##Testing when the covariance matrix is known
#similar to univariate case, lets start with testing means when the covariance is known.
#simulate the samples
meanvect = c(13,5,1250)
cov_m = matrix(c(124,123,47,
123,203,162,
47,162,3257), ncol = 3)
#define a function to sample from a MN dist
set.seed(123)
gen.data = function(mu, sigma, n) {
require(MASS)
dt = mvrnorm(n, mu=mu, Sigma=sigma) #samples
meandt = mean(dt)
return(dt)
}
gen.samples = gen.data(meanvect, cov_m, 300)
colnames(gen.samples) = c("v1", "v2", "v3")
#Testing for one sample
#Lets test the generated sample gen.samples with the null hypothesis mu* = mu = c(10,5,1200)
#Known covariance matrix (we use the covariance of the previous normal distribution)
n = dim(gen.samples)[1]
mu.sam = apply(gen.samples, 2, mean)
mu = c(10, 5, 1200)
z2 = n*t(mu.sam-mu)%*%solve(cov_m)%*%(mu.sam-mu)
p.z2 = dchisq(z2, 3) #Z2 is distributed as chisq(p) if null is true
p.z2
#Using hotellingT2 function from desctools package
HotellingsT2Test(gen.samples, mu = mu)
library(DescTools)
#Using hotellingT2 function from desctools package
HotellingsT2Test(gen.samples, mu = mu)
library(psych)
uts.a = matrix(c(4, 7, 11, 23, 19,
-1, 6, -4, 18, -5,
2, 25, 5, -9, 9,
17, -3, 8, 0, 7,
15, 22, 21, 14, 3), nrow = 5, byrow = T)
uts.b = matrix(c(0, 11, -14, 9,
-1, 14, 2, 6,
-9, -13, 13, 15,
-2, -8, -7, 12,
-12, -15, 8, 4), nrow = 5, byrow = T)
uts.c = matrix(c(11, 15, 7, 0,
8, 3, 16, -1,
10, 12, 14, -2,
5, -3, 4, 13), nrow = 4, byrow = T)
so4 = uts.c%*%t(uts.b)%*%uts.a%*%uts.b
tr(so4)
eigen(so4/256)
library(base)
svd(so4)
data_skor = rbind(uts.b, uts.c)
data_skor
apply(data_skor, 2, mean)
elim = 0
m.skor = apply(data_skor, 2, mean)
dim(data_skor)[2]
m.skor[1]
red.skor = c(0,0,0,0,0,0,0,0,0)
for(i in 1:dim(data_skor)[1]){
for(j in 1:dim(data_skor)[2]){
if(data_skor[i,j] < m.skor[j]){
red.skor[j] = red.skor[j]+1
}
if(red.skor[i] > 2){
elim = elim + 1
}
}
}
elim
red.skor
elim = 0
red.skor = c(0,0,0,0,0,0,0,0,0)
for(i in 1:dim(data_skor)[1]){
for(j in 1:dim(data_skor)[2]){
if(data_skor[i,j] < m.skor[j]){
red.skor[j] = red.skor[j]+1
}
if(red.skor[i] > 2){
elim = elim + 1
}
}
}
elim
red.skor
m.skor = apply(data_skor, 2, mean)
elim = 0
red.skor = c(0,0,0,0,0,0,0,0,0)
for(i in 1:dim(data_skor)[1]){
for(j in 1:dim(data_skor)[2]){
if(data_skor[i,j] < m.skor[j]){
red.skor[j] = red.skor[j]+1
}
}
if(red.skor[i] > 2){
elim = elim + 1
}
}
elim
red.skor
elim = 0
red.skor = c(0,0,0,0,0,0,0,0,0)
elim
red.skor
for(i in 1:dim(data_skor)[1]){
for(j in 1:dim(data_skor)[2]){
if(data_skor[i,j] < m.skor[j]){
red.skor[j] = red.skor[j]+1
}
}
if(red.skor[i] > 2){
elim = elim + 1
}
}
elim
red.skor
red.skor = c(0,0,0,0,0,0,0,0,0)
for(j in 1:dim(data_skor)[2]){
if(data_skor[1,j] < m.skor[j]){
red.skor[j] = red.skor[j]+1
}
}
red.skor
red.skor = c(0,0,0,0,0,0,0,0,0)
red.skor[1]+1
red.skor = c(0,0,0,0,0,0,0,0,0)
for(j in 1:dim(data_skor)[2]){
if(data_skor[1,j] < m.skor[j]){
red.skor[1] = red.skor[1]+1
}
}
red.skor
elim = 0
red.skor = c(0,0,0,0,0,0,0,0,0)
for(i in 1:dim(data_skor)[1]){
for(j in 1:dim(data_skor)[2]){
if(data_skor[1,j] < m.skor[j]){
red.skor[i] = red.skor[i]+1
}
}
if(red.skor[i] > 2){
elim = elim + 1
}
}
elim
red.skor
elim = 0
red.skor = c(0,0,0,0,0,0,0,0,0)
for(i in 1:dim(data_skor)[1]){
for(j in 1:dim(data_skor)[2]){
if(data_skor[i,j] < m.skor[j]){
red.skor[i] = red.skor[i]+1
}
}
if(red.skor[i] > 2){
elim = elim + 1
}
}
elim
red.skor
data_skor = rbind(uts.a[,1:4]uts.b, uts.c)
data_skor = rbind(uts.a[,1:4], uts.b, uts.c)
m.skor = apply(data_skor, 2, mean)
data_skor
m.skor = apply(data_skor, 2, mean)
elim = 0
red.skor = c(0,0,0,0,0,0,0,0,0)
for(i in 1:dim(data_skor)[1]){
for(j in 1:dim(data_skor)[2]){
if(data_skor[i,j] < m.skor[j]){
red.skor[i] = red.skor[i]+1
}
}
if(red.skor[i] > 2){
elim = elim + 1
}
}
elim
red.skor = c(0,0,0,0,0,0,0,0,0,0,0,0,0,0)
for(i in 1:dim(data_skor)[1]){
for(j in 1:dim(data_skor)[2]){
if(data_skor[i,j] < m.skor[j]){
red.skor[i] = red.skor[i]+1
}
}
if(red.skor[i] > 2){
elim = elim + 1
}
}
elim
red.skor
m.skor = apply(data_skor, 2, mean)
elim = 0
red.skor = c(0,0,0,0,0,0,0,0,0,0,0,0,0,0)
for(i in 1:dim(data_skor)[1]){
for(j in 1:dim(data_skor)[2]){
if(data_skor[i,j] < m.skor[j]){
red.skor[i] = red.skor[i]+1
}
}
if(red.skor[i] > 2){
elim = elim + 1
}
}
elim
red.skor
svd(so4)
det(cov(data_skor))
tr(cov(data_skor))
(data_skor[1,]-data_skor[8,])
t(data_skor[1,]-data_skor[8,])%*%solve(cov(data_skor))%*%(data_skor[1,]-data_skor[8,])
read.table("T6_21_CORK.DAT")
cork = read.table("T6_21_CORK.DAT")
svd(cork)
svd(cork[,-1])
eigen(cork[,-1])
eigen(cov(cork[,-1]))
svd(cork[,-1])
eigen(cork[,-1]%*%t(cork[,-1]))
cork.sq = cork[,-1]%*%t(cork[,-1])
cork.sq = as.matrix(cork[,-1])%*%t(as.matrix(cork[,-1]))
eigen(cork.sq)
cork.sq = t(as.matrix(cork[,-1]))%*%as.matrix(cork[,-1])
eigen(cork.sq)
svd(cov(cork[,-1]))
eigen(cov(cork[,-1]))
apply(cork[,-1], 2, mean)
tr(so4)
eigen(so4/256)
elim
det(cov(data_skor))
tr(cov(data_skor))
t(data_skor[1,]-data_skor[8,])%*%solve(cov(data_skor))%*%(data_skor[1,]-data_skor[8,])
eigen(cov(cork[,-1]))
cork.sq = t(as.matrix(cork[,-1]))%*%as.matrix(cork[,-1])
eigen(cork.sq)
eigv.cork = eigen(cov(cork))$vectors
dd = t(eigv.cork)%*%cov(cork%*%eigv.cork
dd[1,2] = 0
dd = t(eigv.cork)%*%cov(cork%*%eigv.cork
dd = t(eigv.cork)%*%cov(cork%*%eigv.cork)
dd = t(eigv.cork)%*%cov(cork%*%eigv.cork)
dd = t(eigv.cork)%*%cov(cork)%*%eigv.cork
dd
diag(diag(dd))
dd = diag(diag(dd))
sqrt_k = eigv.cork%*%sqrt(t(dd))%*%t(eigv.cork)
sqrt_k
sqrt_k%*%t(sqrt_k)
cov(cork)
multt3 = matrix(c(1,-1,1,-1,2,-3,2,-1,-2,2,-3,1,-4,2,3,-2), nrow = 4)
multt3
s.cork = multt3%*%cork
s.cork = cork%*%multt3
s.cork = as.matrix(cork)%*%multt3
s.cork = as.matrix(cork[,-1])%*%multt3
apply(s.cork, 2, mean)
cov(s.cork)
cor(s.cork)
partition(cov(s.cork), rowsep = c(1,3), colsep = c(1,3))
part.s = partition(cov(s.cork), rowsep = c(1,3), colsep = c(1,3))
det(part.s$`1`$1)
det(part.s$`1`$2)
det(part.s$`2`$2)
part.s$`2`$2
part.s$`2`$'2'
det(part.s$`2`$'2')
tr(part.s$`2`$'2')
mean(cork)
mean(cork[,-1])
mahalanobis(cork[,-1],mean = apply(cork, 2, mean), cov(cork))
mahalanobis(cork[,-1],mean = apply(cork[,-1], 2, mean), cov(cork[,-1]))
mahalanobis(cork[,-1], apply(cork[,-1], 2, mean), cov(cork[,-1]))
cork$Mahalanobis2Mean = mahalanobis(cork[,-1], apply(cork[,-1], 2, mean), cov(cork[,-1]))
cork
cork[,-1]

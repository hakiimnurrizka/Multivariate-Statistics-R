scale_color_manual(values = c('black', 'red', 'green')) + labs(x='Feature_1', y="Feature_2")
iris %>% ggplot(aes(Sepal.Length, Petal.Length), color = Species) + geom_point(alpha = 1.8, size = 2.5, col = iris$spec) +
scale_color_manual(values = c('black', 'red', 'green')) + labs(x='Feature_1', y="Feature_2")
#Try projecting the data into each feature
iris %>% ggplot(aes(Sepal.Length, 0), color = Species) + geom_point(alpha = 1.8, size = 2.5, col = iris$spec) +
scale_color_manual(values = c('black', 'red', 'green')) + labs(x='Feature_1', y="Feature_2")
# For the sake of simplicity as to get the points easier to be understood,
#we'll start to illustrate the methods from the linear discriminant.
# We use iris data
data("iris")
iris = iris[100,-c(2,4)]
iris$Species = as.factor(iris$Species)
iris$spec = c(rep(1, 50), rep(2,50))
# For the sake of simplicity as to get the points easier to be understood,
#we'll start to illustrate the methods from the linear discriminant.
# We use iris data
data("iris")
iris = iris[1:100,-c(2,4)]
iris$Species = as.factor(iris$Species)
iris$spec = c(rep(1, 50), rep(2,50))
iris %>% ggplot(aes(Sepal.Length, Petal.Length), color = Species) + geom_point(alpha = 1.8, size = 2.5, col = iris$spec) +
scale_color_manual(values = c('black', 'red', 'green')) + labs(x='Feature_1', y="Feature_2")
#Lets try classify 3 species on the iris data
data("iris")
iris = iris[,-c(2,4)]
iris$spec = c(rep(1, 50), rep(2,50), rep(3,50))
iris %>% ggplot(aes(Sepal.Length, Petal.Length), color = Species) + geom_point(alpha = 1.8, size = 2.5, col = iris$spec) +
scale_color_manual(values = c('black', 'red', 'green')) + labs(x='Feature_1', y="Feature_2")
lda_iris2 = lda(Species ~., data = iris[,-4] )
library(klaR)
library(psych)
library(MASS)
lda_iris2 = lda(Species ~., data = iris[,-4] )
lda_iris2$scaling #Parameter in the discriminant function
plot(lda_iris2)
iris = as.data.frame(cbind(iris, predict(lda_iris)$x))
View(iris)
iris = as.data.frame(cbind(iris, predict(lda_iris2)$x))
#Lets try classify 3 species on the iris data
data("iris")
iris = iris[,-c(2,4)]
iris$spec = c(rep(1, 50), rep(2,50), rep(3,50))
iris %>% ggplot(aes(Sepal.Length, Petal.Length), color = Species) + geom_point(alpha = 1.8, size = 2.5, col = iris$spec) +
scale_color_manual(values = c('black', 'red', 'green')) + labs(x='Feature_1', y="Feature_2")
lda_iris2 = lda(Species ~., data = iris[,-4] )
lda_iris2$scaling
iris = as.data.frame(cbind(iris, predict(lda_iris2)$x))
plot(lda_iris2)
lda_iris2 %>% ggplot(aes(LD1, LD2)) +
geom_point(aes(color = Species))
lda_iris2 %>% ggplot(aes(LD1, LD2)) + geom_point(alpha = 1.8, size = 2.5, col = iris$spec)
lda_iris2 %>% ggplot(aes(LD1, LD2), color = Species) + geom_point(alpha = 1.8, size = 2.5, col = iris$spec) +
scale_color_manual(values = c('black', 'red', 'green')) + labs(x='Feature_1', y="Feature_2")
iris %>% ggplot(aes(LD1, LD2), color = Species) + geom_point(alpha = 1.8, size = 2.5, col = iris$spec) +
scale_color_manual(values = c('black', 'red', 'green')) + labs(x='Feature_1', y="Feature_2")
iris %>% ggplot(aes(LD1, LD2), color = Species) + geom_point(alpha = 1.8, size = 2.5, col = iris$spec) +
scale_color_manual(values = c('black', 'red', 'green')) + labs(x='Linear_Disc1', y="Linear_Disc2")
pred = predict(lda_iris2, iris[,1:2])
ldahist(data = pred$x[,1])
ldahist(data = pred$x[,1], g = iris$spec)
partimat(Species ~. , data = iris[,1:3], method = "lda")
# Quadratic and Mixture DA
# Fit the model
qda_iris = qda(Species~., data = [,-c(4:6)])
# Quadratic and Mixture DA
# Fit the model
qda_iris = qda(Species~., data = iris[,-c(4:6)])
qda_iris$scaling
# Make predictions
pred = predict(qda_iris, iris[,1:2])
# Model accuracy
mean(pred$class == iris$Species)
pred = predict(lda_iris2, iris[,1:2])
mean(pred$class == iris$Species)
library(mda)
# Fit the model
mda_iris = mda(Species~., data = iris[,-c(4:6)])
install.packages("mda")
library(mda)
mda_iris$scaling
# Fit the model
mda_iris = mda(Species~., data = iris[,-c(4:6)])
mda_iris$scaling
mda_iris$
# Make predictions
predicted.classes <- model %>% predict(test.transformed)
mda_iris$values
mda_iris$confusion
pred = predict(mda_iris, iris[,1:2])
# Model accuracy
mean(predicted.classes == test.transformed$Species)
# Model accuracy
mean(pred == iris$Species)
# Make predictions
pred = predict(qda_iris, iris[,1:2])
ldahist(data = pred$x[,1], g = iris$spec)
pred$class
ldahist(data = pred$class, g = iris$Species)
ldahist(data = as.factor(pred$class), g = iris$Species)
pred = predict(lda_iris2, iris[,1:2])
pred$x[,1]
pred$x
# Make predictions
pred = predict(qda_iris, iris[,1:2])
pred$posterior
plot(qda_iris)
# Flexible DA
#Builds the discriminant function by combining non linear predictors such as splines.
#Good to model non-normality or non-linearity relationships among variables within each category
fda_iris = fda(Species~., data = iris[,-c(4:6)])
# Make predictions
pred = predict(fda_iris, iris[,1:2])
# Model accuracy
mean(pred == iris$Species)
# Regularized DA
#Classification rule by regularizing the group covariance matrices (Friedman 1989).
#Tackling multicollinearity problem.
#Can be seen as a trade-off between LDA and QDA, as in shrinking the separate covariance in QDA to incline more
#towards common variance as in LDA.
rda = rda(Species~., data = iris[,-c(4:6)])
rm(rda)
# Regularized DA
#Classification rule by regularizing the group covariance matrices (Friedman 1989).
#Tackling multicollinearity problem.
#Can be seen as a trade-off between LDA and QDA, as in shrinking the separate covariance in QDA to incline more
#towards common variance as in LDA.
rda_iris = rda(Species~., data = iris[,-c(4:6)])
# Make predictions
pred = predict(rda_iris, iris[,1:2])
mean(pred$class == iris$Species)
# LDA assumptions
library(MVN)
#Normality
mvn(iris[,1:2])
library(biotools)
#Homogeneity
boxM(iris[,1:2], iris$Species)
View(client_train)
View(client_train1)
# Fit model
#LDA
lda_client = lda(default.payment.next.month~., data = client_train1)
pred_client = predict(lda_client, client_train1[,1:12])
mean(pred_client$class == client_train1$default.payment.next.month)
#QDA
qda_client = qda(default.payment.next.month~., data = client_train1)
pred2_client = predict(qda_client, client_train1[,1:12])
mean(pred2_client$class == client_train1$default.payment.next.month)
#Separate train for accuracy test
set.seed(12345)
examples = client_train1$default.payment.next.month %>%
createDataPartition(p = 0.1, list = FALSE)
#Separate train for accuracy test
library(caret)
set.seed(12345)
examples = client_train1$default.payment.next.month %>%
createDataPartition(p = 0.1, list = FALSE)
client_train1.1  = client_train1[examples,]
client_train1.2 = client_train1[-examples,]
set.seed(12345)
examples = client_train1$default.payment.next.month %>%
createDataPartition(p = 0.25, list = FALSE)
client_train1.1  = client_train1[examples,]
client_train1.2 = client_train1[-examples,]
# Fit model
#LDA
lda_client = lda(default.payment.next.month~., data = client_train1.1)
pred_client = predict(lda_client, client_train1.2[,1:12])
mean(pred_client$class == client_train1$default.payment.next.month)
mean(pred_client$class == client_train1.2$default.payment.next.month)
#QDA
qda_client = qda(default.payment.next.month~., data = client_train1.1)
pred2_client = predict(qda_client, client_train1.2[,1:12])
mean(pred2_client$class == client_train1.2$default.payment.next.month)
#MDA
mda_client = mda(default.payment.next.month~., data = client_train1.1)
pred3_client = predict(mda_client, client_train1.2)
mean(pred3_client == client_train1.2$default.payment.next.month)
#FDA
fda_client = fda(default.payment.next.month~., data = client_train1.1)
pred4_client = predict(fda_client, client_train1.2)
mean(pred4_client == client_train1.2$default.payment.next.month)
#RDA
rda_client = rda(default.payment.next.month~., data = client_train1.1)
#RDA
rda_client = rda(default.payment.next.month~., data = client_train1.1)
pred5_client = predict(rda_client, client_train1.2)
mean(pred5_client$class == client_train1.2$default.payment.next.month)
# Assumptions
mvn(client_train1.1[,-13])
boxM(client_train1.1[,-13], client_train1.1$default.payment.next.month)
# Summary for accuracy
summarise(accuracy_LDA = mean(pred_client$class == client_train1.2$default.payment.next.month))
# Summary for accuracy
summarize(accuracy_LDA = mean(pred_client$class == client_train1.2$default.payment.next.month))
# Summary for accuracy
DA_accuracy = cbind(mean(pred_client$class == client_train1.2$default.payment.next.month),
mean(pred2_client$class == client_train1.2$default.payment.next.month),
mean(pred3_client$class == client_train1.2$default.payment.next.month),
mean(pred4_client$class == client_train1.2$default.payment.next.month),
mean(pred5_client$class == client_train1.2$default.payment.next.month))
# Summary for accuracy
DA_accuracy = c(mean(pred_client$class == client_train1.2$default.payment.next.month),
mean(pred2_client$class == client_train1.2$default.payment.next.month),
mean(pred3_client$class == client_train1.2$default.payment.next.month),
mean(pred4_client$class == client_train1.2$default.payment.next.month),
mean(pred5_client$class == client_train1.2$default.payment.next.month))
# Summary for accuracy
DA_accuracy = as.array(mean(pred_client$class == client_train1.2$default.payment.next.month),
mean(pred2_client$class == client_train1.2$default.payment.next.month),
mean(pred3_client$class == client_train1.2$default.payment.next.month),
mean(pred4_client$class == client_train1.2$default.payment.next.month),
mean(pred5_client$class == client_train1.2$default.payment.next.month))
# Summary for accuracy
DA_accuracy = as.numeric(mean(pred_client$class == client_train1.2$default.payment.next.month),
mean(pred2_client$class == client_train1.2$default.payment.next.month),
mean(pred3_client$class == client_train1.2$default.payment.next.month),
mean(pred4_client$class == client_train1.2$default.payment.next.month),
mean(pred5_client$class == client_train1.2$default.payment.next.month))
# Summary for accuracy
DA_accuracy = as.array(mean(pred_client$class == client_train1.2$default.payment.next.month),
mean(pred2_client$class == client_train1.2$default.payment.next.month),
mean(pred3_client$class == client_train1.2$default.payment.next.month),
mean(pred4_client$class == client_train1.2$default.payment.next.month),
mean(pred5_client$class == client_train1.2$default.payment.next.month))
names(DA_accuracy) = c("LDA", "QDA", "MDA", "FDA", "RDA")
length(DA_accuracy)
DA_accuracy
# Summary for accuracy
DA_accuracy = as.array(mean(pred_client$class == client_train1.2$default.payment.next.month),
mean(pred2_client$class == client_train1.2$default.payment.next.month),
mean(pred3_client$class == client_train1.2$default.payment.next.month),
mean(pred4_client$class == client_train1.2$default.payment.next.month),
mean(pred5_client$class == client_train1.2$default.payment.next.month))
# Summary for accuracy
DA_accuracy = as.vector(mean(pred_client$class == client_train1.2$default.payment.next.month),
mean(pred2_client$class == client_train1.2$default.payment.next.month),
mean(pred3_client$class == client_train1.2$default.payment.next.month),
mean(pred4_client$class == client_train1.2$default.payment.next.month),
mean(pred5_client$class == client_train1.2$default.payment.next.month))
# Summary for accuracy
DA_accuracy = as.array(mean(pred_client$class == client_train1.2$default.payment.next.month),
mean(pred2_client$class == client_train1.2$default.payment.next.month),
mean(pred3_client$class == client_train1.2$default.payment.next.month),
mean(pred4_client$class == client_train1.2$default.payment.next.month),
mean(pred5_client$class == client_train1.2$default.payment.next.month))
# Summary for accuracy
DA_accuracy = as.array(mean(pred_client$class == client_train1.2$default.payment.next.month))
DA_accuracy+  as.array(mean(pred2_client$class == client_train1.2$default.payment.next.month))
# Summary for accuracy
DA_accuracy = as.data.frame(mean(pred_client$class == client_train1.2$default.payment.next.month),
mean(pred2_client$class == client_train1.2$default.payment.next.month),
mean(pred3_client$class == client_train1.2$default.payment.next.month),
mean(pred4_client$class == client_train1.2$default.payment.next.month),
mean(pred5_client$class == client_train1.2$default.payment.next.month))
lda_acc = mean(pred_client$class == client_train1.2$default.payment.next.month)
qda_acc = mean(pred2_client$class == client_train1.2$default.payment.next.month)
mda_acc = mean(pred3_client == client_train1.2$default.payment.next.month)
fda_acc = mean(pred4_client == client_train1.2$default.payment.next.month)
rda_acc = mean(pred5_client$class == client_train1.2$default.payment.next.month)
# Summary for accuracy
DA_accuracy = as.data.frame(c(lda_acc, qda_acc, mda_acc, fda_acc, rda_acc))
colnames(DA_accuracy) = c("LDA", "QDA", "MDA", "FDA", "RDA")
View(DA_accuracy)
# Summary for accuracy
DA_accuracy = as.data.frame(cbind(lda_acc, qda_acc, mda_acc, fda_acc, rda_acc))
View(DA_accuracy)
colnames(DA_accuracy) = c("LDA", "QDA", "MDA", "FDA", "RDA")
row.names(DA_accuracy) = c("Accuracy")
#From the accuracy and assumptions test, FDA and RDA seems to be the better models compared to the rest
fda_client$confusion
#From the accuracy and assumptions test, FDA and RDA seems to be the better models compared to the rest
sensitivity(fda_client$confusion)
specificity(fda_client$confusion)
#FDA
fda_client = fda(default.payment.next.month~., data = client_train1.1, method = mars)
pred4_client = predict(fda_client, client_train1.2)
fda_acc = mean(pred4_client == client_train1.2$default.payment.next.month)
#From the accuracy and assumptions test, FDA and RDA seems to be the better models compared to the rest
sensitivity(fda_client$confusion)
specificity(fda_client$confusion)
#FDA
fda_client = fda(default.payment.next.month~., data = client_train1.1, method = mars, keep.fitted = TRUE)
pred4_client = predict(fda_client, client_train1.2)
fda_acc = mean(pred4_client == client_train1.2$default.payment.next.month)
# Summary for accuracy
DA_accuracy = as.data.frame(cbind(lda_acc, qda_acc, mda_acc, fda_acc, rda_acc))
colnames(DA_accuracy) = c("LDA", "QDA", "MDA", "FDA", "RDA")
row.names(DA_accuracy) = c("Accuracy")
fda_client$fit$fitted.values
head(fda_client$fit$fitted.values,100)
fda_client$percent.explained[2]/100
fda_client$percent.explained[2]
fda_client$percent.explained
fda_client$fit$fitted.values %>%
as_tibble() %>%
bind_cols("Payment status" = client_train1.1$default.payment.next.month) %>%
ggplot() +
geom_point(aes(V1, V2, color = client_train1.1$default.payment.next.month+1, shape = client_train1.1$default.payment.next.month+1), size = 2.5) +
labs(x = paste("FDA1 (", percent(fda_client$percent.explained[1]/100), ")", sep=""),
y = " " )
client_train1.1$fitted_fda = fda_client$fit$fitted.values
View(client_train1.1)
client_train1.1 %>% ggplot(aes(x = fitted_fda, y = 0), color = default.payment.next.month+1) +
geom_point(alpha = 1.8, size = 2.5, col = client_train1.1$default.payment.next.month) +
scale_color_manual(values = c('black', 'red', 'green')) + labs(x='Flex_Disc1', y=" ")
client_train1.1 %>% ggplot(aes(x = fitted_fda, y = 0), color = default.payment.next.month+1) +
geom_point(alpha = 1.8, size = 2.5, col = client_train1.1$default.payment.next.month+1) +
scale_color_manual(values = c('black', 'red', 'green')) + labs(x='Flex_Disc1', y=" ")
#From the accuracy and assumptions test, FDA and RDA seems to be the better models compared to the rest
fda_client$confusion
specificity(fda_client$confusion)
library(ggord)
ggord(lda_iris2, iris$Species)
ggord(lda_iris2, iris$Species, coord_fix = FALSE)
ggord(lda_iris2, iris$Species, poly = FALSE)
ggord(lda_iris2, iris$Species, poly = FALSE, arrow = NULL)
ggord(lda_iris2, iris$Species, poly = FALSE, arrow = NULL, parse = FALSE)
ggord(lda_iris2, iris$Species, poly = FALSE, arrow = NULL, parse = FALSE, facet = FALSE)
ggord(lda_iris2, iris$Species, ellipse = FALSE)
ggord(lda_iris2, iris$Species, ellipse = FALSE, axes = NULL)
ggord(lda_iris2, iris$Species, ellipse = FALSE, axes = 1)
ggord(lda_iris2, iris$Species, ellipse = FALSE, axes = c("1"))
ggord(lda_iris2, iris$Species, ellipse = FALSE, axes = c("1"."2"))
ggord(lda_iris2, iris$Species, ellipse = FALSE, axes = c("1","2"))
ggord(lda_iris2, iris$Species, ellipse = FALSE, axes = FALSE)
ggord(lda_iris2, iris$Species)
#From the accuracy and assumptions test, FDA and RDA seems to be the better models compared to the rest
fda_client
#From the accuracy and assumptions test, FDA and RDA seems to be the better models compared to the rest
summary(fda_client)
#From the accuracy and assumptions test, FDA and RDA seems to be the better models compared to the rest
performance(fda_client)
View(client_train)
View(client_train1)
View(client_train_new1)
View(client_train1)
View(client_train_new1)
View(client_train)
View(client_train1.2)
View(client_train1.1)
View(client_train1)
View(client_train)
View(client_train_new1)
summary(pca_train1)
View(client_train1)
##Prepare the data
cricket = read.csv("https://raw.githubusercontent.com/housecricket/data/main/efa/sample1.csv")
describe(cricket)
### Factor analysis ###
library(psych)
library(corrplot)
library(ggplot2)
library(car)
library(nFactors)
describe(cricket)
View(client_train)
View(head(pca_train1$x,7))
fviz_eig(pca_train1)
library(factoextra)
fviz_eig(pca_train1)
summary(pca_train1)
fviz_pca_ind(pca_train1, col.ind = "cos2", # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = T)
fviz_pca_var(pca_train1, col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)
fviz_eig(pca_train1)
describe(cricket)
##Kaiser-Meyer-Olkin measure of sampling adequacy
#(to determine whether factor analysis will be useful or not)
#The threshold for the measure value from Kaiser(1974) is
#0.00 to 0.49 unacceptable.
#0.50 to 0.59 miserable.
#0.60 to 0.69 mediocre.
#0.70 to 0.79 middling.
#0.80 to 0.89 meritorious.
#0.90 to 1.00 marvelous.
KMO(cricket2)
cricket2 = cricket1[,-13]
cricket1 = cricket[,-1]
corrplot(matcrick, method = "number")
##Correlation matrix
matcrick = cor(cricket1[,-13])
corrplot(matcrick, method = "number")
cricket2 = cricket1[,-13]
##Kaiser-Meyer-Olkin measure of sampling adequacy
#(to determine whether factor analysis will be useful or not)
#The threshold for the measure value from Kaiser(1974) is
#0.00 to 0.49 unacceptable.
#0.50 to 0.59 miserable.
#0.60 to 0.69 mediocre.
#0.70 to 0.79 middling.
#0.80 to 0.89 meritorious.
#0.90 to 1.00 marvelous.
KMO(cricket2)
#Check the determinant of the correlation matrix of the data,
#positive value indicate that factor analysis will run just fine
det(cor(cricket2))
##Determine number of factors
fa_crick = fa(cricket1, nfactors = ncol(cricket2), rotate = "none")
n_fa = length(fa_crick$e.values)
scree_fa = data.frame(
factor_n = as.factor(1:n_fa),
eigenvalues = fa_crick$e.values
)
ggplot(scree_fa, aes(x = factor_n, y = eigenvalues, group = 1))+
geom_point()+geom_line()+xlab("number of factors")+ylab("initial eigenvalue")+
labs(title = "scree plot", subtitle = "(based on unreduced correlation matrix)")
fa.parallel(cricket2)
##Using factanal
factanal(cricket2, factors = 4, rotation ="varimax", scores = c("regression"))
install.packages("lavaan")
## CFA Using lavaan
library(lavaan)
install.packages("foreign")
library(foreign)
library(haven)
SAQ <- read_sav("G:/My Drive/Github/Multivariate-Statistics-R/SAQ.sav")
View(SAQ)
SAQ1 = SAQ[,1:8]
View(SAQ1)
cor(SAQ1)
library(corrplot)
corrplot(SAQ1)
SAQ1 =na.omit(SAQ[,1:8]) #we'll only use first 8 questions
View(SAQ1)
corrplot(SAQ1)
corrplot(SAQ1[,1:2])
corrplot(cor(SAQ1))
## CFA Using lavaan
library(lavaan)
library(corrplot)
corrplot(cor(SAQ1))
## One factor - 3 items
fac1_3 = 'f =~ q03+q04+q05'
mfac1_3 = cfa(fac1_3, data = SAQ1)
summary(mfac1_3)
#we can set marker method to fixed other parameter by defining NA*parameter
fac1_3 = 'f =~ q03+q04+NA*q05'
mfac1_3 = cfa(fac1_3, data = SAQ1)
summary(mfac1_3)
#we can set marker method to fixed other parameter by defining NA*parameter
fac1_3 = 'f =~ q03+q04+NA*q05
q05 ~ 1'
mfac1_3 = cfa(fac1_3, data = SAQ1)
summary(mfac1_3)
#we can set marker method to fixed other parameter by defining NA*parameter
fac1_3 = 'f =~ q03+q04+1*q05'
mfac1_3 = cfa(fac1_3, data = SAQ1)
summary(mfac1_3)
#we can set marker method to fixed other parameter by defining NA*parameter
fac1_3 = 'f =~ NA*q03+q04+1*q05'
mfac1_3 = cfa(fac1_3, data = SAQ1)
summary(mfac1_3)
#For better understanding of the factor, we can add standardize in the summary function
summary(mfac1_3, standardized = TRUE)
## One factor - 2 items
#To fit such model, we need variance standardization that is to set the variance of factor to one and equate
#both factor loadings.
fac1_2 = 'f1 =~ a*q04 + a*q05'
mfac1_2 = cfa(fac1_2, data = SAQ1)
summary(mfac1_2, standardized = TRUE)
mfac1_2 = cfa(fac1_2, data = SAQ1, std.lv = TRUE)
summary(mfac1_2, standardized = TRUE)
## One factor - >3 items
fac1 = 'f =~ q01 + q02 + q03 + q04 + q05 + q06 + q07 + q08'
mfac1 = cfa(fac1, data =SAQ1, std.lv = TRUE)
summary(mfac1, fit.measures = TRUE, standardized = TRUE)
### Clustering ###
library(factoextra)
library(cluster)
library(ggplot2)
library(dplyr)
### CFA Using lavaan
library(lavaan)
library(haven)
library(corrplot)
summary(mfac1, fit.measures = TRUE, standardized = TRUE)
## Two or more factors
#For case where we assume there are more than 1 factor, there are 3 conditions to consider : (1)uncorrelated
#factors, (2)correlated factors, and (3)hierarchy/order of factors.
#For the (1) case we simply assume that each factor is uncorrelated with each other. Lets say for previous
#anxiety data we have 2 uncorrelated factors, thus the model :
fac2 = 'f1 =~ q01 +  q03 + q04 + q05 + q08
f2 =~ a*q06 + a*q07
f1 ~~ 0*f2'
mfac2 = cfa(fac2, data = SAQ1, std.lv = TRUE)
summary(mfac2, fit.measures = TRUE, standardized = TRUE)
#From the result above, model fit measurements show that 2 factors model with uncorrelated factors poorly fits
#the data. It is also has higher test statistics of chi-square and RMSEA than the previous one factor model.
#We can then try 2 factors model with correlated factors.
#Case (2) we assume there is strong correlation between 2 factors behind the anxiety data. The model for
#2 correlated factors is :
fac2_c = 'f1 =~ q01 +  q03 + q04 + q05 + q08
f2 =~ q06 + q07'
mfac2_c = cfa(fac2_c, data = SAQ1, std.lv = TRUE)
summary(mfac2_c, fit.measures = TRUE, std.lv = TRUE)
summary(mfac2_c, fit.measures = TRUE, standardized = TRUE)
#The result above shows some contradiction on the test statistics where RMSEA decide that the model is a close
#fitting for the data while chi square decide that the model is not a close fit. This is a normal occurrence
#since the chi square statistics tends to reject null hypothesis easily when the number observations is high.
#But all in all, when we also consider the fit measures from CFI and TLI, this 2 correlated factors is by far
#the best model for anxiety data compared to previous models.
#For the last case (3), we may consider that instead of 2 factors being correlated, there is another factor
#that affects both factors. In other words, we have a structure that is ordered from : exogenous factor which
#affects the endogenous factors which then these endogenous factors affects our item/data.
#The model is simply adding another layer of factor equation on the endogenous factors.
fac2_o = 'f1 =~ q01 +  q03 + q04 + q05 + q08
f2 =~ q06 + q07
f3 =~ a*f1 + a*f2'
mfac2_o = cfa(fac2_o, data = SAQ1, std.lv = TRUE)
summary(mfac2_o, fit.measures = TRUE, standardized = TRUE)
